{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Find the emission pathways that caused the change in air quality over 2015-2017 in China**\n",
    "- Per gridcell (emulator).  \n",
    "- Remove the inputs that don't predict the correct change.  \n",
    "\n",
    "##### **Steps**\n",
    "1. Load observations for 1 station.  \n",
    "2. Find the change in measured PM2.5 (annual-mean) and O3 (6mDM8h) concentrations for this location over 2015-2017.  \n",
    "3. Filter through predictions of all emission configurations for this location. \n",
    "4. Keep emission configurations where the prediction matchs (within 1%) the measured change in PM2.5/O3 concentrations.  \n",
    "5. Split by region.  \n",
    "6. Compare to bottom-up estimates.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tabula\n",
    "import joblib\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 700,\n",
    "    'font.size': 12,\n",
    "    'text.usetex': True,\n",
    "    'figure.figsize': [5, 5],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bottom up emissions 2015-2017 - Zheng et al., 2018 ACP\n",
    "df = tabula.read_pdf('/nfs/b0122/Users/earlacoa/paper_aia_china/emulator_annual/zheng2018.pdf', pages=7)\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 4', 'Unnamed: 9', 'c'], inplace=True)\n",
    "df.columns = ['sector', 'so2', 'nox', 'nmvoc', 'nh3', 'co', 'tsp', 'pm10', 'pm25', 'bc', 'oc', 'co2']\n",
    "\n",
    "df_2010 = df.iloc[0:7].copy()\n",
    "df_2011 = df.iloc[7:14].copy()\n",
    "df_2012 = df.iloc[14:21].copy()\n",
    "df_2013 = df.iloc[21:28].copy()\n",
    "df_2014 = df.iloc[28:35].copy()\n",
    "df_2015 = df.iloc[35:42].copy()\n",
    "df_2016 = df.iloc[42:49].copy()\n",
    "df_2017 = df.iloc[49:56].copy()\n",
    "\n",
    "df_2010.set_index('sector', inplace=True)\n",
    "df_2011.set_index('sector', inplace=True)\n",
    "df_2012.set_index('sector', inplace=True)\n",
    "df_2013.set_index('sector', inplace=True)\n",
    "df_2014.set_index('sector', inplace=True)\n",
    "df_2015.set_index('sector', inplace=True)\n",
    "df_2016.set_index('sector', inplace=True)\n",
    "df_2017.set_index('sector', inplace=True)\n",
    "\n",
    "df_2010 = df_2010.astype('float32').copy()\n",
    "df_2011 = df_2011.astype('float32').copy()\n",
    "df_2012 = df_2012.astype('float32').copy()\n",
    "df_2013 = df_2013.astype('float32').copy()\n",
    "df_2014 = df_2014.astype('float32').copy()\n",
    "df_2015 = df_2015.astype('float32').copy()\n",
    "df_2016 = df_2016.astype('float32').copy()\n",
    "df_2017 = df_2017.astype('float32').copy()\n",
    "\n",
    "df_diff = ((100 * df_2017 / df_2015) - 100).copy()\n",
    "df_diff.drop(['2015', '2017'], inplace=True)\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_lon</th>\n",
       "      <th>name</th>\n",
       "      <th>prefecture</th>\n",
       "      <th>o3_6mDM8h_ppb</th>\n",
       "      <th>PM2_5_DRY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>2653A</td>\n",
       "      <td>37.93580</td>\n",
       "      <td>102.6469</td>\n",
       "      <td>Leitai</td>\n",
       "      <td>Wuwei, Gansu</td>\n",
       "      <td>38.148829</td>\n",
       "      <td>34.739530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>2444A</td>\n",
       "      <td>30.90750</td>\n",
       "      <td>113.9420</td>\n",
       "      <td>Dongcheng District</td>\n",
       "      <td>Xiaogan</td>\n",
       "      <td>45.937878</td>\n",
       "      <td>67.907879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>1435A</td>\n",
       "      <td>30.68500</td>\n",
       "      <td>104.0740</td>\n",
       "      <td>Liangjiaxiang</td>\n",
       "      <td>Chengdu</td>\n",
       "      <td>55.021252</td>\n",
       "      <td>57.145726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>1987A</td>\n",
       "      <td>31.17200</td>\n",
       "      <td>120.6580</td>\n",
       "      <td>Wujiang Development Zone</td>\n",
       "      <td>Wu Jiang</td>\n",
       "      <td>53.349313</td>\n",
       "      <td>52.923839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>2183A</td>\n",
       "      <td>37.52110</td>\n",
       "      <td>111.1406</td>\n",
       "      <td>Environmental Protection Agency</td>\n",
       "      <td>Lu Liang</td>\n",
       "      <td>42.435293</td>\n",
       "      <td>37.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>2332A</td>\n",
       "      <td>26.63830</td>\n",
       "      <td>118.1694</td>\n",
       "      <td>Nanping City Monitoring Station</td>\n",
       "      <td>Nanping</td>\n",
       "      <td>45.923116</td>\n",
       "      <td>21.420337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>3005A</td>\n",
       "      <td>34.29000</td>\n",
       "      <td>117.1814</td>\n",
       "      <td>Gulou District Government</td>\n",
       "      <td>Xuzhou</td>\n",
       "      <td>62.576291</td>\n",
       "      <td>53.881156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1355A</td>\n",
       "      <td>23.55380</td>\n",
       "      <td>113.5890</td>\n",
       "      <td>Hat Peak Mountain Forest Park</td>\n",
       "      <td>Guangzhou</td>\n",
       "      <td>61.745821</td>\n",
       "      <td>24.190048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1900A</td>\n",
       "      <td>29.34110</td>\n",
       "      <td>104.7692</td>\n",
       "      <td>Chunhua Road</td>\n",
       "      <td>Zigong</td>\n",
       "      <td>49.227893</td>\n",
       "      <td>48.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>3021A</td>\n",
       "      <td>35.76806</td>\n",
       "      <td>115.0061</td>\n",
       "      <td>Lishui River Management Office</td>\n",
       "      <td>Fuyang</td>\n",
       "      <td>65.796138</td>\n",
       "      <td>62.709456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8165 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           station_id  station_lat  station_lon  \\\n",
       "datetime                                          \n",
       "2015-01-01      2653A     37.93580     102.6469   \n",
       "2015-01-01      2444A     30.90750     113.9420   \n",
       "2015-01-01      1435A     30.68500     104.0740   \n",
       "2015-01-01      1987A     31.17200     120.6580   \n",
       "2015-01-01      2183A     37.52110     111.1406   \n",
       "...               ...          ...          ...   \n",
       "2019-01-01      2332A     26.63830     118.1694   \n",
       "2019-01-01      3005A     34.29000     117.1814   \n",
       "2019-01-01      1355A     23.55380     113.5890   \n",
       "2019-01-01      1900A     29.34110     104.7692   \n",
       "2019-01-01      3021A     35.76806     115.0061   \n",
       "\n",
       "                                       name    prefecture  o3_6mDM8h_ppb  \\\n",
       "datetime                                                                   \n",
       "2015-01-01                           Leitai  Wuwei, Gansu      38.148829   \n",
       "2015-01-01               Dongcheng District       Xiaogan      45.937878   \n",
       "2015-01-01                    Liangjiaxiang       Chengdu      55.021252   \n",
       "2015-01-01         Wujiang Development Zone      Wu Jiang      53.349313   \n",
       "2015-01-01  Environmental Protection Agency      Lu Liang      42.435293   \n",
       "...                                     ...           ...            ...   \n",
       "2019-01-01  Nanping City Monitoring Station       Nanping      45.923116   \n",
       "2019-01-01        Gulou District Government        Xuzhou      62.576291   \n",
       "2019-01-01    Hat Peak Mountain Forest Park     Guangzhou      61.745821   \n",
       "2019-01-01                     Chunhua Road        Zigong      49.227893   \n",
       "2019-01-01   Lishui River Management Office        Fuyang      65.796138   \n",
       "\n",
       "            PM2_5_DRY  \n",
       "datetime               \n",
       "2015-01-01  34.739530  \n",
       "2015-01-01  67.907879  \n",
       "2015-01-01  57.145726  \n",
       "2015-01-01  52.923839  \n",
       "2015-01-01  37.413166  \n",
       "...               ...  \n",
       "2019-01-01  21.420337  \n",
       "2019-01-01  53.881156  \n",
       "2019-01-01  24.190048  \n",
       "2019-01-01  48.094556  \n",
       "2019-01-01  62.709456  \n",
       "\n",
       "[8165 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obs = pd.read_csv(\n",
    "    '/nfs/a68/earlacoa/china_measurements_corrected/df_obs_o3_6mDM8h_ppb_PM2_5_DRY.csv',\n",
    "    index_col='datetime',\n",
    "    parse_dates=True\n",
    ")\n",
    "df_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['o3_6mDM8h_ppb', 'PM2_5_DRY']\n",
    "\n",
    "obs_files = glob.glob('/nfs/a68/earlacoa/china_measurements_corrected/*.nc')\n",
    "\n",
    "path_predictions = '/nfs/b0122/Users/earlacoa/paper_aia_china/emulator_annual/predictions'\n",
    "\n",
    "matrix_stacked = np.array(np.meshgrid(\n",
    "    np.linspace(0.2, 1.3, 12), # np.linspace(0.0, 1.5, 16) for 0.0-1.5\n",
    "    np.linspace(0.2, 1.3, 12), # np.linspace(0.2, 1.3, 12) for 0.2-1.3\n",
    "    np.linspace(0.2, 1.3, 12), # removing edges of parameter space 0.0, 0.1, 1.4, 1.5\n",
    "    np.linspace(0.2, 1.3, 12),\n",
    "    np.linspace(0.2, 1.3, 12)\n",
    ")).T.reshape(-1, 5)\n",
    "\n",
    "obs_change_abs = {}\n",
    "obs_change_per = {}\n",
    "baselines = {}\n",
    "targets = {}\n",
    "station_diffs_abs = {}\n",
    "station_diffs_per = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in outputs:\n",
    "    for obs_file in obs_files:\n",
    "        station_id = obs_file[47:-3]\n",
    "        lat = df_obs.loc[df_obs.station_id == station_id].station_lat.unique()[0]\n",
    "        lon = df_obs.loc[df_obs.station_id == station_id].station_lon.unique()[0]\n",
    "        \n",
    "        change_per = 100 * ((df_obs.loc[df_obs.station_id == station_id][output]['2017'].values[0] / \\\n",
    "                             df_obs.loc[df_obs.station_id == station_id][output]['2015'].values[0]) - 1)\n",
    "        change_abs = df_obs.loc[df_obs.station_id == station_id][output]['2017'].values[0] - \\\n",
    "                     df_obs.loc[df_obs.station_id == station_id][output]['2015'].values[0]\n",
    "\n",
    "        obs_change_abs.update({f'{station_id}_{output}': change_abs})\n",
    "        obs_change_per.update({f'{station_id}_{output}': change_per})\n",
    "\n",
    "        if output == 'o3_6mDM8h_ppb':\n",
    "            emulator_output = 'o3_6mDM8h'\n",
    "        else:\n",
    "            emulator_output = output\n",
    "            \n",
    "        with xr.open_dataset(\n",
    "            f'{path_predictions}/{emulator_output}/ds_RES1.0_IND1.0_TRA1.0_AGR1.0_ENE1.0_{emulator_output}_popgrid_0.25deg.nc'\n",
    "        )[emulator_output] as ds:\n",
    "            baseline = ds.sel(lat=lat, method='nearest').sel(lon=lon, method='nearest').values\n",
    "                    \n",
    "        baselines.update({f'{station_id}_{output}': baseline})\n",
    "\n",
    "        target_abs = baseline + change_abs\n",
    "        target_per = baseline * (1 + (change_per / 100))\n",
    "        target = np.mean([target_abs, target_per])\n",
    "        targets.update({f'{station_id}_{output}': target})\n",
    "        \n",
    "        target_diffs_abs = {}\n",
    "        target_diffs_per = {}\n",
    "        \n",
    "        for matrix in matrix_stacked:\n",
    "            inputs = matrix.reshape(-1, 5)        \n",
    "            filename = f'RES{inputs[0][0]:.1f}_IND{inputs[0][1]:.1f}_TRA{inputs[0][2]:.1f}_AGR{inputs[0][3]:.1f}_ENE{inputs[0][4]:.1f}'\n",
    "            with xr.open_dataset(\n",
    "                f'{path_predictions}/{emulator_output}/ds_{filename}_{emulator_output}_popgrid_0.25deg.nc'\n",
    "            )[emulator_output] as ds:\n",
    "                prediction = ds.sel(lat=lat, method='nearest').sel(lon=lon, method='nearest').values\n",
    "\n",
    "            target_diff_abs = targets[f'{station_id}_{output}'] - prediction\n",
    "            target_diff_per = (100 * (prediction / targets[f'{station_id}_{output}'])) - 100\n",
    "            \n",
    "            if abs(target_diff_per) < 1: # +/- 1% of target\n",
    "                target_diffs_abs.update({filename: target_diff_abs})\n",
    "                target_diffs_per.update({filename: target_diff_per})\n",
    "\n",
    "        station_diffs_abs.update({f'{station_id}_{output}': target_diffs_abs})\n",
    "        station_diffs_per.update({f'{station_id}_{output}': target_diffs_per})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in [key for key in targets.keys()]:\n",
    "#     if np.isnan(targets[key]):\n",
    "#         del targets[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_diffs = {}\n",
    "for key in [key for key in targets.keys()]:\n",
    "    target_diffs.update({key: targets[key] - baselines[key]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in list(set([key for key in emulators.keys()]) - set([key for key in targets.keys()])):\n",
    "#     del emulators[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [list(station_diffs_per[station].keys())for station in station_diffs_per.keys()]\n",
    "keys_flatten = [item for sublist in keys for item in sublist]\n",
    "keys_unique = {}\n",
    "for key in keys_flatten:\n",
    "    if key not in keys_unique:\n",
    "        keys_unique.update({key: 1})\n",
    "    elif key in keys_unique:\n",
    "        keys_unique.update({key: keys_unique[key] + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/b0122/Users/earlacoa/paper_aia_china/emulator_annual/find_emissions_that_match_change_air_quality/2015-2017'\n",
    "\n",
    "joblib.dump(targets, f'{path}/targets.joblib')\n",
    "joblib.dump(baselines, f'{path}/baselines.joblib')\n",
    "joblib.dump(target_diffs, f'{path}/target_diffs.joblib')\n",
    "joblib.dump(obs_change_abs, f'{path}/obs_change_abs.joblib')\n",
    "joblib.dump(obs_change_per, f'{path}/obs_change_per.joblib')\n",
    "joblib.dump(keys_unique, f'{path}/keys_unique.joblib')\n",
    "joblib.dump(station_diffs_per, f'{path}/station_diffs_per_1percent.joblib')\n",
    "joblib.dump(station_diffs_abs, f'{path}/station_diffs_abs_1percent.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/b0122/Users/earlacoa/paper_aia_china/emulator_annual/find_emissions_that_match_change_air_quality/2015-2017'\n",
    "\n",
    "targets = joblib.load(f'{path}/targets.joblib')\n",
    "baselines = joblib.load(f'{path}/baselines.joblib')\n",
    "target_diffs = joblib.load(f'{path}/target_diffs.joblib')\n",
    "station_diffs_per = joblib.load(f'{path}/station_diffs_per_1percent.joblib')\n",
    "station_diffs_abs = joblib.load(f'{path}/station_diffs_abs_1percent.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_provinces = {\n",
    "    'Beijing': 'North China',\n",
    "    'Tianjin': 'North China',\n",
    "    'Hebei': 'North China',\n",
    "    'Shanxi': 'North China',\n",
    "    'Nei Mongol': 'North China',\n",
    "    'Liaoning': 'North East China',\n",
    "    'Jilin': 'North East China',\n",
    "    'Heilongjiang': 'North East China',\n",
    "    'Shanghai': 'East China',\n",
    "    'Jiangsu': 'East China',\n",
    "    'Zhejiang': 'East China', \n",
    "    'Anhui': 'East China', \n",
    "    'Fujian': 'East China', \n",
    "    'Jiangxi': 'East China', \n",
    "    'Shandong': 'East China',\n",
    "    'Taiwan': 'East China',\n",
    "    'Henan': 'South Central China',\n",
    "    'Hubei': 'South Central China',\n",
    "    'Hunan': 'South Central China',\n",
    "    'Guangdong': 'South Central China',\n",
    "    'Guangxi': 'South Central China',\n",
    "    'Hainan': 'South Central China',\n",
    "    'Hong Kong': 'South Central China',\n",
    "    'Macao': 'South Central China',\n",
    "    'Chongqing': 'South West China',\n",
    "    'Sichuan': 'South West China',\n",
    "    'Guizhou': 'South West China',\n",
    "    'Yunnan': 'South West China',\n",
    "    'Xizang': 'South West China',\n",
    "    'Shaanxi': 'North West China',\n",
    "    'Gansu': 'North West China', \n",
    "    'Qinghai': 'North West China',\n",
    "    'Ningxia Hui': 'North West China',\n",
    "    'Xinjiang Uygur': 'North West China'\n",
    "}\n",
    "\n",
    "gba_prefectures = ['Dongguan', 'Foshan', 'Guangzhou', 'Huizhou', 'Jiangmen', 'Shenzhen', 'Zhaoqing', 'Zhongshan', 'Zhuhai', 'Hong Kong', 'Macao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_prefectures_china = gpd.read_file('/nfs/a68/earlacoa/shapefiles/china/gadm36_CHN_3.shp')\n",
    "# gdf_prefectures_hongkong = gpd.read_file('/nfs/a68/earlacoa/shapefiles/hongkong/gadm36_HKG_1.shp')\n",
    "# gdf_prefectures_macao = gpd.read_file('/nfs/a68/earlacoa/shapefiles/macao/gadm36_MAC_2.shp')\n",
    "\n",
    "# list_prefectures_gba = []\n",
    "# for gba_prefecture in gba_prefectures:\n",
    "#     list_prefectures_gba.append(gdf.loc[gdf.NAME_2 == gba_prefecture])\n",
    "\n",
    "\n",
    "# list_prefectures_gba.append(gdf_prefectures_hongkong)\n",
    "# list_prefectures_gba.append(gdf_prefectures_macao)\n",
    "    \n",
    "# gdf_prefectures_gba = pd.concat(list_prefectures_gba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_lats = {}\n",
    "obs_lons = {}\n",
    "obs_provinces = {}\n",
    "obs_prefectures = {}\n",
    "obs_regions = {}\n",
    "obs_gba = {}\n",
    "  \n",
    "for obs_file in obs_files:\n",
    "    with xr.open_dataset(obs_file) as ds:\n",
    "        key = ds.station\n",
    "        if '.nc' in key:\n",
    "            key = key[:-3]\n",
    "            \n",
    "        if key in targets:\n",
    "            obs_lats.update({key: ds.lat})\n",
    "            obs_lons.update({key: ds.lon})\n",
    "            prefecture, province = ds.city.split(', ')\n",
    "            obs_provinces.update({key: province})\n",
    "            obs_prefectures.update({key: prefecture})\n",
    "            obs_regions.update({key: regional_provinces[province]})           \n",
    "            if (prefecture in gba_prefectures) or (prefecture == 'Hong Kong') or (prefecture == 'Macao'):\n",
    "                obs_gba.update({key: True})\n",
    "            else:\n",
    "                obs_gba.update({key: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['China', 'GBA', 'North China', 'North East China', 'East China', 'South Central China', 'South West China', 'North West China']\n",
    "region_stations = {key: [] for key in regions}\n",
    "\n",
    "for station_id, station_region in obs_regions.items():\n",
    "    region_stations['China'].append(station_id)\n",
    "    region_stations[station_region].append(station_id)\n",
    "    \n",
    "    if obs_gba[station_id] == True:\n",
    "        region_stations['GBA'].append(station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_targets = {}\n",
    "regional_baselines = {}\n",
    "regional_target_diffs = {}\n",
    "regional_station_diffs_per = {}\n",
    "regional_station_diffs_abs = {}\n",
    "\n",
    "for region in regions:\n",
    "    regional_targets.update({region: dict((key, value) for key, value in targets.items() if key in region_stations[region])})\n",
    "    regional_baselines.update({region: dict((key, value) for key, value in baselines.items() if key in region_stations[region])})\n",
    "    regional_target_diffs.update({region: dict((key, value) for key, value in target_diffs.items() if key in region_stations[region])})\n",
    "    regional_station_diffs_per.update({region: dict((key, value) for key, value in station_diffs_per.items() if key in region_stations[region])})\n",
    "    regional_station_diffs_abs.update({region: dict((key, value) for key, value in station_diffs_abs.items() if key in region_stations[region])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_keys_unique_sorted = {}\n",
    "regional_target_diffs_under0p5 = {}\n",
    "\n",
    "for region in regions:\n",
    "    keys = [list(regional_station_diffs_per[region][station_id].keys()) for station_id in regional_station_diffs_per[region].keys()]\n",
    "    keys_flatten = [item for sublist in keys for item in sublist]\n",
    "\n",
    "    keys_unique = {}\n",
    "    for key in keys_flatten:\n",
    "        if key not in keys_unique:\n",
    "            keys_unique.update({key: 1})\n",
    "        elif key in keys_unique:\n",
    "            keys_unique.update({key: keys_unique[key] + 1})\n",
    "\n",
    "\n",
    "    keys_unique_sorted = {key: value for key, value in sorted(keys_unique.items(), key=lambda item: item[1], reverse=True)}\n",
    "    regional_keys_unique_sorted.update({region: keys_unique_sorted})\n",
    "    \n",
    "    target_diffs_under0p5 = {}\n",
    "    for key, value in regional_target_diffs[region].items():\n",
    "        if abs(value) < 0.5:\n",
    "            target_diffs_under0p5.update({key: value})\n",
    "            \n",
    "    \n",
    "    regional_target_diffs_under0p5.update({region: target_diffs_under0p5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_stations = {}\n",
    "number_of_emission_configurations = {}\n",
    "first_emission_configuration_keys = {}\n",
    "second_emission_configuration_keys = {}\n",
    "third_emission_configuration_keys = {}\n",
    "first_emission_configuration_values = {}\n",
    "second_emission_configuration_values = {}\n",
    "third_emission_configuration_values = {}\n",
    "number_of_stations_with_target_diff_under_0p5 = {}\n",
    "\n",
    "for region in regional_targets.keys():\n",
    "    number_of_stations.update({region: len(regional_targets[region].keys())})\n",
    "    number_of_emission_configurations.update({region: len(regional_keys_unique_sorted[region].keys())})\n",
    "    top3_emission_configurations = list(islice(regional_keys_unique_sorted[region].items(), 3))\n",
    "    first_emission_configuration_keys.update({region: top3_emission_configurations[0][0]})\n",
    "    second_emission_configuration_keys.update({region: top3_emission_configurations[1][0]})\n",
    "    third_emission_configuration_keys.update({region: top3_emission_configurations[2][0]})\n",
    "    first_emission_configuration_values.update({region: top3_emission_configurations[0][1]})\n",
    "    second_emission_configuration_values.update({region: top3_emission_configurations[1][1]})\n",
    "    third_emission_configuration_values.update({region: top3_emission_configurations[2][1]})\n",
    "    number_of_stations_with_target_diff_under_0p5.update({region: len(regional_target_diffs_under0p5[region])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.concat([\n",
    "    pd.Series(number_of_stations, name='Stations'),\n",
    "    pd.Series(number_of_emission_configurations, name='Possible Emission Configurations'),\n",
    "    pd.Series(first_emission_configuration_keys, name='First Emission Configuration - Key'),\n",
    "    pd.Series(first_emission_configuration_values, name='First Emission Configuration - Value'),\n",
    "    pd.Series(second_emission_configuration_keys, name='Second Emission Configuration - Key'),\n",
    "    pd.Series(second_emission_configuration_values, name='Second Emission Configuration - Value'),\n",
    "    pd.Series(third_emission_configuration_keys, name='Third Emission Configuration - Key'),\n",
    "    pd.Series(third_emission_configuration_values, name='Third Emission Configuration - Value'),\n",
    "    pd.Series(number_of_stations_with_target_diff_under_0p5, name='Stations with trend size under 0.5 ugm-3')\n",
    "], axis=1)\n",
    "df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions.to_csv(f'{path}/df_regions_1percent.csv')\n",
    "joblib.dump(regional_keys_unique_sorted, f'{path}/regional_keys_unique_sorted_1percent.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.read_csv(f'{path}/df_regions_1percent.csv')\n",
    "regional_keys_unique_sorted = joblib.load(f'{path}/regional_keys_unique_sorted_1percent.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'China'\n",
    "factors_res = {}\n",
    "factors_ind = {}\n",
    "factors_tra = {}\n",
    "factors_agr = {}\n",
    "factors_ene = {}\n",
    "\n",
    "for index, items in enumerate(list(itertools.islice(regional_keys_unique_sorted[region].items(), 100))):\n",
    "    factor_res, factor_ind, factor_tra, factor_agr, factor_ene = [float(item) for item in re.findall('\\d+\\.\\d+',  items[0])]\n",
    "    factors_res.update({index: factor_res})\n",
    "    factors_ind.update({index: factor_ind})\n",
    "    factors_tra.update({index: factor_tra})\n",
    "    factors_agr.update({index: factor_agr})\n",
    "    factors_ene.update({index: factor_ene})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(index, keys, values, sector):\n",
    "    ax = fig.add_subplot(gs[index])\n",
    "    ax.set_facecolor('whitesmoke')\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0.3, 1.2])\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xlabel('Rank', fontsize=14)\n",
    "    plt.ylabel('Emission factor', fontsize=14)\n",
    "    plt.title(sector)\n",
    "    plt.scatter(keys, values)\n",
    "    plt.annotate(r'\\textbf{' + chr(97 + index) + '}', xy=(0,1.05), xycoords='axes fraction', fontsize=14, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(12, 8))\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "\n",
    "make_plot(0, factors_res.keys(), factors_res.values(), 'RES')\n",
    "make_plot(1, factors_ind.keys(), factors_ind.values(), 'IND')\n",
    "make_plot(2, factors_tra.keys(), factors_tra.values(), 'TRA')\n",
    "make_plot(3, factors_agr.keys(), factors_agr.values(), 'AGR')\n",
    "make_plot(4, factors_ene.keys(), factors_ene.values(), 'ENE')\n",
    "\n",
    "gs.tight_layout(fig, rect=[0, 0, 0.85, 0.85])\n",
    "#plt.savefig('/nfs/b0122/Users/earlacoa/png/paper_aia_emulator_annual/emission_factors_vs_rank.png', dpi=700, alpha=True, bbox_inches='tight')\n",
    "#plt.savefig('/nfs/b0122/Users/earlacoa/png/paper_aia_emulator_annual/emission_factors_vs_rank.eps', format='eps', dpi=700, alpha=True, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxplot(index, values, sector, bottomup):\n",
    "    ax = fig.add_subplot(gs[index])\n",
    "    ax.set_facecolor('whitesmoke')\n",
    "    plt.ylim([0.2, 1.3])\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    if index == 0:\n",
    "        plt.ylabel('Emission factor', fontsize=14)\n",
    "    else:\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.title(sector)\n",
    "    color1 = '#c7eae5'\n",
    "    color2 = '#01665e'\n",
    "    plt.boxplot(\n",
    "        values, \n",
    "        patch_artist=True,\n",
    "        boxprops={'facecolor': color1, 'color': color2, 'linewidth': 1.5},\n",
    "        capprops={'color': color2, 'linewidth': 1.5},\n",
    "        whiskerprops={'color': color2, 'linewidth': 1.5},\n",
    "        flierprops={'color': color2, 'markeredgecolor': color2, 'linewidth': 1.5},\n",
    "        medianprops={'color': color2, 'linewidth': 1.5},\n",
    "        showmeans=True,\n",
    "        meanprops={'markeredgecolor': color2, 'color': color2},\n",
    "        showfliers=False,\n",
    "        whis=(5, 95),\n",
    "        zorder=1\n",
    "    )\n",
    "    plt.scatter(1, bottomup, color='#8c510a', zorder=2, marker='*')\n",
    "    plt.annotate(r'\\textbf{' + chr(97 + index) + '}', xy=(0, 1.05), xycoords='axes fraction', fontsize=14, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhang2018_bottomup20152017_allspecies_res = 1 + (df_diff.loc['Residential'][['so2', 'nox', 'nmvoc', 'nh3', 'co', 'pm25', 'bc', 'oc', 'pm10']].mean() / 100)\n",
    "zhang2018_bottomup20152017_allspecies_ind = 1 + (df_diff.loc['Industry'][['so2', 'nox', 'nmvoc', 'nh3', 'co', 'pm25', 'bc', 'oc', 'pm10']].mean() / 100)\n",
    "zhang2018_bottomup20152017_allspecies_tra = 1 + (df_diff.loc['Transportation'][['so2', 'nox', 'nmvoc', 'nh3', 'co', 'pm25', 'bc', 'oc', 'pm10']].mean() / 100)\n",
    "zhang2018_bottomup20152017_allspecies_agr = 1 + (df_diff.loc['Agriculture'][['so2', 'nox', 'nmvoc', 'nh3', 'co', 'pm25', 'bc', 'oc', 'pm10']].mean() / 100)\n",
    "zhang2018_bottomup20152017_allspecies_ene = 1 + (df_diff.loc['Power'][['so2', 'nox', 'nmvoc', 'nh3', 'co', 'pm25', 'bc', 'oc', 'pm10']].mean() / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(15, 3))\n",
    "gs = gridspec.GridSpec(1, 5)\n",
    "\n",
    "make_boxplot(0, factors_res.values(), 'RES', zhang2018_bottomup20152017_allspecies_res)\n",
    "make_boxplot(1, factors_ind.values(), 'IND', zhang2018_bottomup20152017_allspecies_ind)\n",
    "make_boxplot(2, factors_tra.values(), 'TRA', zhang2018_bottomup20152017_allspecies_tra)\n",
    "make_boxplot(3, factors_agr.values(), 'AGR', zhang2018_bottomup20152017_allspecies_agr)\n",
    "make_boxplot(4, factors_ene.values(), 'ENE', zhang2018_bottomup20152017_allspecies_ene)\n",
    "\n",
    "gs.tight_layout(fig, rect=[0, 0, 0.65, 0.85])\n",
    "\n",
    "# plt.annotate(r'\\textbf{Boxplot: }', xy=(-4.6, -0.15), xycoords='axes fraction', fontsize=14, color='#01665e')\n",
    "# plt.annotate('5$^{th}$, 25$^{th}$, 50$^{th}$, 75$^{th}$, 95$^{th}$ percentiles', xy=(-4.0, -0.15), xycoords='axes fraction', fontsize=14, color='#01665e')\n",
    "# plt.annotate(r'\\textbf{$\\Delta$: }', xy=(-4.222, -0.25), xycoords='axes fraction', fontsize=14, color='#01665e')\n",
    "# plt.annotate('Top-down mean (emulator, species: CO, NO$_X$, SO$_2$, NH$_3$, BC, OC, PM$_{2.5}$, PM$_{10}$, NMVOC)', xy=(-4.0, -0.25), xycoords='axes fraction', fontsize=14, color='#01665e')\n",
    "# plt.annotate(r'\\textbf{$\\star$: }', xy=(-4.21, -0.35), xycoords='axes fraction', fontsize=14, color='#8c510a')\n",
    "# plt.annotate('Bottom-up mean (Zhang et al., 2018, ACP, species: CO, NO$_X$, SO$_2$, NH$_3$, BC, OC, PM$_{2.5}$, PM$_{10}$, NMVOC)', xy=(-4.0, -0.35), xycoords='axes fraction', fontsize=14, color='#8c510a')\n",
    "\n",
    "plt.annotate(r'\\textbf{$\\Delta$: Top-down from emulators}', xy=(-4.0, -0.15), xycoords='axes fraction', fontsize=14, color='#01665e')\n",
    "plt.annotate('', xy=(-4.0, -0.25), xycoords='axes fraction', fontsize=14, color='#01665e')\n",
    "plt.annotate(r'\\textbf{$\\star$: Bottom-up from Zheng et al., (2018)}', xy=(-2.0, -0.15), xycoords='axes fraction', fontsize=14, color='#8c510a')\n",
    "\n",
    "#plt.savefig('/nfs/b0122/Users/earlacoa/png/paper_aia_emulator_annual/emission_factors_boxplot_top100_1percent.png', dpi=700, alpha=True, bbox_inches='tight')\n",
    "#plt.savefig('/nfs/b0122/Users/earlacoa/png/paper_aia_emulator_annual/emission_factors_boxplot_top100_1percent.eps', format='eps', dpi=700, alpha=True, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(zhang2018_bottomup20152017_allspecies_res, 2))\n",
    "print(round(zhang2018_bottomup20152017_allspecies_ind, 2))\n",
    "print(round(zhang2018_bottomup20152017_allspecies_tra, 2))\n",
    "print(round(zhang2018_bottomup20152017_allspecies_agr, 2))\n",
    "print(round(zhang2018_bottomup20152017_allspecies_ene, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color1 = '#c7eae5'\n",
    "color2 = '#01665e'\n",
    "bp = plt.boxplot(\n",
    "    factors_ene.values(), \n",
    "    patch_artist=True,\n",
    "    boxprops={'facecolor': color1, 'color': color2, 'linewidth': 1.5},\n",
    "    capprops={'color': color2, 'linewidth': 1.5},\n",
    "    whiskerprops={'color': color2, 'linewidth': 1.5},\n",
    "    flierprops={'color': color2, 'markeredgecolor': color2, 'linewidth': 1.5},\n",
    "    medianprops={'color': color2, 'linewidth': 1.5},\n",
    "    showmeans=True,\n",
    "    meanprops={'markeredgecolor': color2, 'color': color2},\n",
    "    showfliers=False,\n",
    "    whis=(5, 95),\n",
    "    zorder=1\n",
    ")\n",
    "round(bp['means'][0].get_ydata()[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
