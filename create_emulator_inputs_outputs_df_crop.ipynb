{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop the simulator data to China only\n",
    "#### Create dataframe of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = pd.read_csv('/nfs/see-fs-02_users/earlacoa/emulator/latin_hypercube_inputs_train.csv')\n",
    "inputs_test = pd.read_csv('/nfs/see-fs-02_users/earlacoa/emulator/latin_hypercube_inputs_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nfs/b0122/Users/earlacoa/paper_aia_china/'\n",
    "\n",
    "sectors = ['RES', 'IND', 'TRA', 'AGR', 'POW']\n",
    "outputs = ['PM2_5_DRY', 'o3', 'AOD550_sfc', 'asoaX_2p5', 'bc_2p5', 'bsoaX_2p5', 'nh4_2p5', 'no3_2p5', 'oc_2p5', 'oin_2p5', 'so4_2p5']\n",
    "\n",
    "sims_train = []\n",
    "sims_test = []\n",
    "\n",
    "for sim_number in range(1, 51):\n",
    "    sims_train.extend(['t' + str(sim_number)])\n",
    "    \n",
    "for sim_number in range(51, 56):\n",
    "    sims_test.extend(['t' + str(sim_number)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_china(path, sim, time, output, shapes_china):\n",
    "    \"\"\"Crop DataArray to given shapefile for specific output\"\"\"\n",
    "    with xr.open_dataset(path + sim + '/wrfout_d01_global_0.25deg_2015-' + time + '_' + output + '.nc') as ds:\n",
    "        try:\n",
    "            conc = ds[output]\n",
    "        except KeyError:    \n",
    "            conc = ds['__xarray_dataarray_variable__']\n",
    "            conc.name = output\n",
    "            \n",
    "        lon = ds.lon.values\n",
    "        lat = ds.lat.values\n",
    "\n",
    "    # mark shapefiles with 1 or np.nan (needs the extra step)\n",
    "    conc['china'] = rasterize(shapes_china, conc.coords, longitude='lon', latitude='lat') # in shapefile == 0, outside == np.nan\n",
    "    conc['china'] = conc['china'].where(cond=conc.china!=0, other=1) # if condition (outside china, as inside == 0) preserve, otherwise (1, to mark in china)\n",
    "    \n",
    "    # if condition is shapefile (==1) or not (!=1) preserve, otherwise replace with\n",
    "    conc = conc.where(cond=conc.china==1, other=np.nan) # if condition (in china) preserve, otherwise (np.nan)\n",
    "\n",
    "    return conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_from_latlon(lat, lon):\n",
    "    \"\"\" input 1D array of lat / lon and output an Affine transformation \"\"\"\n",
    "    lat = np.asarray(lat)\n",
    "    lon = np.asarray(lon)\n",
    "    trans = Affine.translation(lon[0], lat[0])\n",
    "    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n",
    "    \n",
    "    return trans * scale\n",
    "\n",
    "\n",
    "def rasterize(shapes, coords, latitude='latitude', longitude='longitude',\n",
    "              fill=np.nan, **kwargs):\n",
    "    \"\"\"Rasterize a list of (geometry, fill_value) tuples onto the given\n",
    "    xray coordinates. This only works for 1d latitude and longitude\n",
    "    arrays.\n",
    "\n",
    "    usage:\n",
    "    -----\n",
    "    1. read shapefile to geopandas.GeoDataFrame\n",
    "          `states = gpd.read_file(shp_dir+shp_file)`\n",
    "    2. encode the different shapefiles that capture those lat-lons as different\n",
    "        numbers i.e. 0.0, 1.0 ... and otherwise np.nan\n",
    "          `shapes = (zip(states.geometry, range(len(states))))`\n",
    "    3. Assign this to a new coord in your original xarray.DataArray\n",
    "          `ds['states'] = rasterize(shapes, ds.coords, longitude='X', latitude='Y')`\n",
    "\n",
    "    arguments:\n",
    "    ---------\n",
    "    : **kwargs (dict): passed to `rasterio.rasterize` function\n",
    "\n",
    "    attrs:\n",
    "    -----\n",
    "    :transform (affine.Affine): how to translate from latlon to ...?\n",
    "    :raster (numpy.ndarray): use rasterio.features.rasterize fill the values\n",
    "      outside the .shp file with np.nan\n",
    "    :spatial_coords (dict): dictionary of {\"X\":xr.DataArray, \"Y\":xr.DataArray()}\n",
    "      with \"X\", \"Y\" as keys, and xr.DataArray as values\n",
    "\n",
    "    returns:\n",
    "    -------\n",
    "    :(xr.DataArray): DataArray with `values` of nan for points outside shapefile\n",
    "      and coords `Y` = latitude, 'X' = longitude.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    transform = transform_from_latlon(coords[latitude], coords[longitude])\n",
    "    out_shape = (len(coords[latitude]), len(coords[longitude]))\n",
    "    raster = features.rasterize(shapes, out_shape=out_shape,\n",
    "                                fill=fill, transform=transform,\n",
    "                                dtype=float, **kwargs)\n",
    "    spatial_coords = {latitude: coords[latitude], longitude: coords[longitude]}\n",
    "    \n",
    "    return xr.DataArray(raster, coords=spatial_coords, dims=(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_china = gpd.read_file('/nfs/a68/earlacoa/shapefiles/china/china_taiwan_hongkong_macao.shp')\n",
    "shapes_china = [(shape, n) for n, shape in enumerate(shp_china.geometry)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train = {}\n",
    "\n",
    "for sim in sims_train:\n",
    "    for index, output in enumerate(outputs):\n",
    "        if output == 'o3':\n",
    "            time = '6mDM8h'\n",
    "        else:\n",
    "            time = 'annual-mean'\n",
    "            \n",
    "        conc = crop_china(path, sim, time, output, shapes_china)\n",
    "        \n",
    "        if index == 0:\n",
    "            df_sim = conc.to_dataframe().dropna().reset_index()[['lat', 'lon']]\n",
    "        \n",
    "        df_sim[output] = conc.to_dataframe().dropna().reset_index()[output]\n",
    "        \n",
    "        if output == 'o3':\n",
    "            df_sim[output] = df_sim[output] * 1000\n",
    "\n",
    "        dict_train.update({sim: df_sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test = {}\n",
    "\n",
    "for sim in sims_test:\n",
    "    for index, output in enumerate(outputs):\n",
    "        if output == 'o3':\n",
    "            time = '6mDM8h'\n",
    "        else:\n",
    "            time = 'annual-mean'\n",
    "            \n",
    "        conc = crop_china(path, sim, time, output, shapes_china)\n",
    "        \n",
    "        if index == 0:\n",
    "            df_sim = conc.to_dataframe().dropna().reset_index()[['lat', 'lon']]\n",
    "        \n",
    "               \n",
    "        df_sim[output] = conc.to_dataframe().dropna().reset_index()[output]\n",
    "        \n",
    "        if output == 'o3':\n",
    "            df_sim[output] = df_sim[output] * 1000\n",
    "\n",
    "        dict_test.update({sim: df_sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfs/a336/earlacoa/paper_aia_china/emulator_annual/dict_train.pickle', 'wb') as ds:\n",
    "    pickle.dump(dict_train, ds, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfs/a336/earlacoa/paper_aia_china/emulator_annual/dict_test.pickle', 'wb') as ds:\n",
    "    pickle.dump(dict_test, ds, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat(dict_train, ignore_index=True)\n",
    "df_test = pd.concat(dict_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('/nfs/a336/earlacoa/paper_aia_china/emulator_annual/dict_train.csv')\n",
    "df_test.to_csv('/nfs/a336/earlacoa/paper_aia_china/emulator_annual/dict_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
